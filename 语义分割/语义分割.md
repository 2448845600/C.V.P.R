# 语义分割

Semantic Segmentation 简单说就是像素级别的目标检测

[TOC]

## 简述

[summaries](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)

### 历史进程

1. [FCN](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)
2. [SegNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#segnet)
3. [Dilated Convolutions](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation)
4. [DeepLab (v1 & v2)](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab)
5. [RefineNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#refinenet)
6. [PSPNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#pspnet)
7. [Large Kernel Matters](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#large-kernel)
8. [DeepLab v3](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplabv3)
9. Auto DeepLab


### 评价标准

FCN 论文 Results 部分总结了以下四个评价标准。定义 $n_{ij}$ 为属于种类 i 的所有像素中，被预测为 种类 j 的数量；定义 $t_i$ 为种类 i 的所有像素被分类的数量， $t_i = \sum_j n_{ij}$ 。

- pixel accuracy，像素精度，预测正确的像素点数除以所有类别的像素点：

${\sum_i  n_{ii}} / {\sum_i t_i}$

- mean accuraccy，平均精度，计算每一类的精度，对所有类取平均：

$(1/n_{cl})\sum_i n_{ii} / t_i$

- mean IU，平均IU，每一类预测正确的数量除以其他类预测该类的数量与该类预测错了数量之和，对所有类取平均：

$(1/n_{cl})\sum_i n_{ii} / (t_i + \sum_j n_{ji} - n_{ii})$

- frequency weighted IU，频率加权IU，在mean IU的基础上，乘以每一类的数量：

$(\sum_k t_k)^{-1} \sum_it_in_{ii} / (t_i + \sum_j n_{ji} - n_{ii})$

## FCN

### 参考

[参考博客1](https://blog.csdn.net/sinat_24143931/article/details/78696442)

[参考博客2](https://zhuanlan.zhihu.com/p/22308032)

[参考博客3](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)

[参考博客4  shift and stitch](https://www.jianshu.com/p/e534e2be5d7d)

[池化层BP推导](https://blog.csdn.net/qq_21190081/article/details/72871704)

[CV系列文章 FCN](https://github.com/lartpang/Machine-Deep-Learning/blob/master/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A3%80%E6%B5%8B/FCN%E6%80%BB%E7%BB%93(2015).md)

Jonathan Long 等人的《Fully Convolutional Networks for Semantic Segmentation》是深度学习在语义分割上的开山之作。FCN对图像进行像素级的分类，从而解决了语义分割。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN（FCN似乎是这篇文章先提出的：OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks）可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的 feature map 进行上采样， 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测，同时保留了原始输入图像中的空间信息，最后在上采样的特征图上进行逐像素分类。主要贡献如下：
- Popularize the use of end to end convolutional networks for semantic segmentation
- Re-purpose imagenet pretrained networks for segmentation
- Upsample using deconvolutional layers
- Introduce skip connections to improve over the coarseness of upsampling

[//]:#(!(https://user-images.githubusercontent.com/20456381/51221623-47eb9400-1975-11e9-95a6-c8331345e51c.png))

[//]:#(中等大小图片!kSMqK0.md.png(https://s2.ax1x.com/2019/01/16/kSMqK0.md.png))

![kSMqK0.png](https://s2.ax1x.com/2019/01/16/kSMqK0.png)



### Why FCN
CNN在语义分割中有一个问题：“网络的输出不匹配”，即比如说416 * 416的输入，经过池化层，全连接层的处理，输出肯定小于416 * 416。所以我们需要先卷积（conv），然后反卷积（deconv，现在一般不称其为反卷积，transposed convolution更为贴切）

[//]:#(!(https://user-images.githubusercontent.com/20456381/51221575-0f4bba80-1975-11e9-957a-cb8a49d6ecca.png))

![kSMtjx.png](https://s2.ax1x.com/2019/01/16/kSMtjx.png)



这样，FCN论文可以说定义了一种通用语义分割结构。



为什么采用FCN

- 输出不匹配
- 任意输入大小
- end to end

   得到语义分割通用结构 “卷积-反卷积” 的FCN

### deconvolution

- **上采样层**  比较了几种方法/技巧，最终采用 deconvolution，即翻转卷积层的前向传播和反向传播，使其可以增加输出大小，同时，该层参数可学习。

- 训练 
	CNN 一般将整张图片作为网络的输入进行训练，即 whole image train。而语义分割需要将图像中的所有像素分类，故认为输入整张图片会有很多冗余，所以采用 patchwise train，即对一个像素，以它为中心取一个patch（相当于裁剪后的小图片），这个 patch 作为网络的输入，网络的输出为该像素的标签。该方法提高了训练了速度，而且通过适当的 sampling 方法来选取 patches 作为训练集，可以平衡类别和解决空间相关性等问题。
	本文通过实验，认为通过 weighting the loss and loss sampling，whole image train也可以达到平衡类别，解决空间相关性和加快训练速度，故 FCN 采用 whole image trian.

### skip connections

卷积的过程，一直在减小输出的尺寸，最后一层输出的特征图信息丢失了很多，作者利用多个尺寸的特征图，叠加后上采样得到预测结果。以 FCN-16s 为例，将con7得到的1 * 1的特征图上采样为 2 * 2 之后和 pool4 之后的 2 * 2 的特征图组合，得到 16 倍上采样得到最终结果（即与输入相同的尺寸的输出）。

![kSfvwt.png](https://s2.ax1x.com/2019/01/16/kSfvwt.png)

### tricks on training

## SegNet




