# 语义分割

Semantic Segmentation 简单说就是像素级别的目标检测

[TOC]

## 简述

[summaries](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)

### 历史进程

1. [FCN](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)
2. [SegNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#segnet)
3. [Dilated Convolutions](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation)
4. [DeepLab (v1 & v2)](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab)
5. [RefineNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#refinenet)
6. [PSPNet](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#pspnet)
7. [Large Kernel Matters](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#large-kernel)
8. [DeepLab v3](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplabv3)
9. Auto DeepLab


### 评价标准

FCN 论文 Results 部分总结了以下四个评价标准。定义 $n_{ij}$ 为属于种类 i 的所有像素中，被预测为 种类 j 的数量；定义 $t_i$ 为种类 i 的所有像素被分类的数量， $t_i = \sum_j n_{ij}$ 。

- pixel accuracy，像素精度，预测正确的像素点数除以所有类别的像素点：

${\sum_i  n_{ii}} / {\sum_i t_i}$

- mean accuraccy，平均精度，计算每一类的精度，对所有类取平均：

$(1/n_{cl})\sum_i n_{ii} / t_i$

- mean IU，平均IU，每一类预测正确的数量除以其他类预测该类的数量与该类预测错了数量之和，对所有类取平均：

$(1/n_{cl})\sum_i n_{ii} / (t_i + \sum_j n_{ji} - n_{ii})$

- frequency weighted IU，频率加权IU，在mean IU的基础上，乘以每一类的数量：

$(\sum_k t_k)^{-1} \sum_it_in_{ii} / (t_i + \sum_j n_{ji} - n_{ii})$

## FCN

[参考博客1](https://blog.csdn.net/sinat_24143931/article/details/78696442)

[参考博客2](https://zhuanlan.zhihu.com/p/22308032)

[参考博客3](http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn)

[参考博客4  shift and stitch](https://www.jianshu.com/p/e534e2be5d7d)

[池化层BP推导](https://blog.csdn.net/qq_21190081/article/details/72871704)

[CV系列文章 FCN](https://github.com/lartpang/Machine-Deep-Learning/blob/master/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A3%80%E6%B5%8B/FCN%E6%80%BB%E7%BB%93(2015).md)

Jonathan Long 等人的《Fully Convolutional Networks for Semantic Segmentation》是深度学习在语义分割上的开山之作。FCN对图像进行像素级的分类，从而解决了语义分割。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN（FCN似乎是这篇文章先提出的：OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks）可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的 feature map 进行上采样， 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测，同时保留了原始输入图像中的空间信息，最后在上采样的特征图上进行逐像素分类。主要贡献如下：
- Popularize the use of end to end convolutional networks for semantic segmentation
- Re-purpose imagenet pretrained networks for segmentation
- Upsample using deconvolutional layers
- Introduce skip connections to improve over the coarseness of upsampling

![](https://raw.githubusercontent.com/2448845600/CV-PaperReading/master/image/FCN.png?token=ATgjvbJKuHuZX1wTZ0K8NZkQu6P6EZ_Bks5cPXYDwA%3D%3D)





Why FCN
CNN在语义分割中有一个问题：“网络的输出不匹配”，即比如说416 * 416的输入，经过池化层，全连接层的处理，输出肯定小于416 * 416。所以我们需要先卷积（conv），然后反卷积（deconv，现在一般不称其为反卷积，transposed convolution更为贴切）

![](https://raw.githubusercontent.com/2448845600/CV-PaperReading/master/image/net1.png?token=ATgjvUyppXKI-JO2_oKJpfpZZ__rVTyLks5cPXZbwA%3D%3D)



这样，FCN论文可以说定义了一种通用语义分割结构。



为什么采用FCN

- 输出不匹配
- 任意输入大小
- end to end

   得到语义分割通用结构 “卷积-反卷积” 的FCN

将传统的CNN转变为语义分割的FCN

- **上采样层** 
- pre-train 可迁移

skip connections

code